

# 7.9 Queue: Sequential List



## Queue Basic Concepts

### What is the queue?

•A type of linear table: queue  
•FIFO: First In First Out  
•Difference from Stack: FILO (First In Last Out)  

![01](https://github.com/knightsummon/02-Computer-underlying-programming-and-system-optimization/blob/main/07%20Embedded%20Data%20Structures%20and%20Linux%20Kernel%20Object%20Orientation/7.9%20Queue%20Sequential%20List.assets/01.jpg)

### Basic Elements of Queue

•Team leader: front  
•Tail of the queue: rear  

![02](https://github.com/knightsummon/02-Computer-underlying-programming-and-system-optimization/blob/main/07%20Embedded%20Data%20Structures%20and%20Linux%20Kernel%20Object%20Orientation/7.9%20Queue%20Sequential%20List.assets/02.jpg)

### When are Queue Used?

#### Asynchronous Communication:

Asynchronous communication is a mode of communication where tasks or processes don't have to happen in real-time or synchronously. Instead, they can operate independently, and their execution doesn't depend on strict timing or coordination. Asynchronous communication is commonly used in various software systems, including web applications and distributed systems, to improve efficiency and responsiveness.

There are three different Asynchronous Communication Situationes.

1. **Message Queues**:

   Message queues are a type of queue used for asynchronous communication between different parts of a system or between distributed systems. Here's how they work:

   - A sender (producer) places a message into the queue, which contains information or instructions for some processing.
   - The receiver (consumer) retrieves messages from the queue at its own pace and processes them when it's ready.
   - This decouples the sender and receiver, allowing them to work independently and without waiting for each other.

   Message queues are often used for tasks like processing background jobs, distributing tasks across multiple servers, and ensuring fault tolerance in distributed systems.

2. **Event Queues**:

   Event-driven systems use event queues to handle asynchronous events. Here's how it works:

   - Events, such as user interactions or system notifications, are added to an event queue.
   - Event handlers (consumers) listen to the queue and process events as they arrive.
   - Events can be processed in the order they were added to the queue or based on priorities.

   Event queues are commonly used in graphical user interfaces (GUIs) and event-driven programming, where responsiveness and event handling are critical.

3. **Task Queues**:

   Task queues are used to manage asynchronous tasks or jobs. Here's how they function:

   - Tasks are added to the queue, often representing work that needs to be done in the background.
   - Worker processes (consumers) pick up tasks from the queue and execute them, typically on separate threads or processes.
   - This allows for parallel processing of tasks, efficient resource utilization, and scalability.

   Task queues are essential in scenarios like web servers handling multiple incoming requests, where tasks like request processing, database queries, or sending emails can be offloaded to a queue for asynchronous execution.

### Queue Storage

- **Sequential Queue**:

    A "Sequential Queue" is a basic implementation of a queue data structure. It follows the First-In-First-Out (FIFO) principle, meaning that the first element added to the queue is the first one to be removed. Here are the key characteristics of a Sequential Queue:

    **Storage**: Elements are typically stored in a contiguous block of memory, often implemented as an array. This ensures efficient access to elements based on their position in the queu

- **Chained Queue**:
  The term "Chained Queue" is not a standard data structure in computer science. However, it could be interpreted in a few different ways:
  **Linked List Queue**: In some contexts, "Chained Queue" might refer to a queue implemented using a linked list data structure. In this case, each element in the queue is a node of the linked list, and each node points to the next element in the queue. This allows for dynamic resizing and efficient memory utilization.
  **Queue within a Chain**: In other cases, "Chained Queue" could be used to describe a queue that is part of a larger chain of data structures or components within a system. This implies that the queue is just one element in a more extensive system architecture.

## The Operations of Queue

```c
#include<stdio.h>
#include<stdlib.h>

#define Queue_SIZE  5

struct queue{
	int data[5]; //data is a array name
	int size; // the actual length of the Queue, every time a valid data saved, size increase one number.
	int front;
	int rear;
};

void init_queue(struct queue *q) // as you can see, for int front and int rear, it all is both zero.
{
	q->front = 0;
	q->rear  = 0;
	q->size  = 0;
}

int is_queue_empty(struct queue *Q)
{
	return (Q->size == 0);
} 
int is_queue_full(struct queue *Q)
{
	return (Q->size == Queue_SIZE);
} 

int enqueue(struct queue *q, int value)
{
	if(is_queue_full(q))
	{
		printf("enqueue failed : Queue is full!\n");
		return -1;
	}
	q->data[q->rear] = value;
	q->size++;	
	q->rear = (q->rear+1)%Queue_SIZE;
	return 0;
}

int dequeue(struct queue *q)
{
	int data;
	if(is_queue_empty(q))
	{
		printf("dequeue failed : Empty queue!\n");
		return -1;
	}
	data = q->data[q->front];
	q->size--;
	q->front = (q->front+1)%Queue_SIZE;

	return data;
}

int print_queue(struct queue *q)
{
	int i = q->front;
	if(is_queue_empty(q))
		return 1;
	do{
		printf("Queue.data[%d] = %d\n",i,q->data[i]);
		i=(i+1)%5;
	}while(i != q->rear);
	return 0;
}


int main(void)
{
	struct queue Queue; // Create the Queue in Memory Space
	
	init_queue(&Queue);// Initialize a Pointer to the Queue.
	
	enqueue(&Queue,1);
	enqueue(&Queue,2);
	enqueue(&Queue,3);
	enqueue(&Queue,4);
	enqueue(&Queue,5);
//	print_queue(&Queue);
//	enqueue(&Queue,6);
//	print_queue(&Queue);
	dequeue(&Queue);
	dequeue(&Queue);
	dequeue(&Queue);
//	dequeue(&Queue);
//	dequeue(&Queue);
//	dequeue(&Queue);
//	print_queue(&Queue);
	enqueue(&Queue,5);
	enqueue(&Queue,6);
	enqueue(&Queue,7);
//	enqueue(&Queue,8);
	print_queue(&Queue);
}
```

```c
struct queue{
	int data[5]; //data is a array name
	int size; // the actual length of the Queue, every time a valid data saved, size increase one number.
	int front;
	int rear;
};

void init_queue(struct queue *q) // as you can see, for int front and int rear, it all is both zero.
{
	q->front = 0;
	q->rear  = 0;
	q->size  = 0;
}
```

![03](https://github.com/knightsummon/02-Computer-underlying-programming-and-system-optimization/blob/main/07%20Embedded%20Data%20Structures%20and%20Linux%20Kernel%20Object%20Orientation/7.9%20Queue%20Sequential%20List.assets/03.jpg)

```c
int enqueue(struct queue *q, int value)
{
	if(is_queue_full(q))
	{
		printf("enqueue failed : Queue is full!\n");
		return -1;
	}
	q->data[q->rear] = value;// Insert the data at the rear
	q->size++;	
	q->rear = (q->rear+1)%Queue_SIZE; //wrap up the queue in case overflowing
	return 0;
}
```

The line of code `q->rear = (q->rear+1)%Queue_SIZE;` is typically used in a queue data structure to update the rear (end) pointer of the queue after enqueuing (adding) an element. Let's break down this line step by step:

1. `q->rear`: This part of the code accesses the `rear` member of the `struct` pointed to by the pointer `q`. In C, when you have a pointer `q`, and you want to access a member of the struct it points to, you use the `->` operator. So, `q->rear` is essentially accessing the rear pointer of the queue.
2. `q->rear+1`: This part of the code increments the current value of `q->rear` by 1. It's increasing the rear pointer to move it to the next position in the queue.
3. `(q->rear+1)%Queue_SIZE`: This part of the code calculates the new rear position while ensuring that it stays within the bounds of the queue's capacity. `Queue_SIZE` likely represents the maximum size or capacity of the queue. The modulo operator `%` is used to wrap around the rear pointer if it exceeds the queue's capacity.
   - Example: If `Queue_SIZE` is 5, and `q->rear` is 4 (the last position in the queue), then `(q->rear+1)%Queue_SIZE` would be equal to `(4+1)%5`, which is 0. This wraps the rear pointer back to the start of the queue because it's a circular queue.
4. `q->rear = ...`: Finally, this part assigns the newly calculated rear position back to the `rear` member of the queue. So, the rear pointer is updated to the next position, considering the circular nature of the queue if applicable.

![04](https://github.com/knightsummon/02-Computer-underlying-programming-and-system-optimization/blob/main/07%20Embedded%20Data%20Structures%20and%20Linux%20Kernel%20Object%20Orientation/7.9%20Queue%20Sequential%20List.assets/04.jpg)

So you can see `int dequeue(struct queue *q)` complements with enqueue, deleting element from the front of the queue, meeting the standard "First in First Out (FIFO)"

![05](https://github.com/knightsummon/02-Computer-underlying-programming-and-system-optimization/blob/main/07%20Embedded%20Data%20Structures%20and%20Linux%20Kernel%20Object%20Orientation/7.9%20Queue%20Sequential%20List.assets/05.jpg)
